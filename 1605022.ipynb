{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = np.loadtxt(\"data.txt\", dtype=float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs.reshape(-1,1)\n",
    "\n",
    "# obs[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramfile = \"parameters.txt\"\n",
    "states = 0\n",
    "with open(paramfile) as f:\n",
    "    states = int(f.readline().strip())\n",
    "\n",
    "\n",
    "trans_p = np.loadtxt(paramfile , dtype = float , skiprows = 1 , max_rows = states )\n",
    "\n",
    "means = np.loadtxt(paramfile , dtype = float , skiprows = states + 1  , max_rows = 1 ).reshape(-1,1)\n",
    "\n",
    "sd = np.loadtxt(paramfile , dtype = float , skiprows = states + 2  , max_rows = 1 ).reshape(-1,1)\n",
    "# trans_p\n",
    "# means[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros([states,1] , float)\n",
    "b[states-1][0] = 1\n",
    "\n",
    "trans_p_copy = np.copy(trans_p)\n",
    "a = trans_p_copy[:,:states-1]\n",
    "\n",
    "\n",
    "for i in range(0,states-1):\n",
    "    a[i][i] = a[i][i] - 1\n",
    "\n",
    "a = np.vstack((a , np.ones([states,1]))).reshape(states,states)\n",
    "\n",
    "start_p = np.linalg.solve(a , b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_probability(transition_matrix):\n",
    "    d = np.zeros([states,1] , float)\n",
    "    d[states-1][0] = 1\n",
    "\n",
    "    transition_matrix_copy = np.copy(transition_matrix)\n",
    "    c = transition_matrix_copy[:,:states-1]\n",
    "\n",
    "\n",
    "    for i in range(0,states-1):\n",
    "        c[i][i] = c[i][i] - 1\n",
    "\n",
    "    c = np.vstack((c, np.ones([states,1]))).reshape(states,states)\n",
    "\n",
    "    init_prob = np.linalg.solve(c , d)\n",
    "\n",
    "    return init_prob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_dist(x , mean , sd):\n",
    "    prob_density = norm.pdf(x, loc=mean, scale=np.sqrt(sd))\n",
    "    if prob_density == 0:\n",
    "        prob_density = 1e-250\n",
    "    return prob_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi():\n",
    "\n",
    "    problist = np.zeros([len(obs), states])\n",
    "    prevlist = np.zeros([len(obs), states])\n",
    "\n",
    "    for state in range(states):\n",
    "        problist[0][state] = np.log(start_p[state] * normal_dist(obs[0][0] , means[0][0], sd[0][0]))\n",
    "        prevlist[0][state] = -1\n",
    "\n",
    "  \n",
    "    for t in range(1, len(obs)):\n",
    "        \n",
    "        for state in range(states):\n",
    "            max_tr_prob = problist[t-1][0] + np.log(trans_p[0][state])\n",
    "            prev_state_selected = 0\n",
    "\n",
    "            for prev_state in range(1,states):\n",
    "                tr_prob = problist[t - 1][prev_state] + np.log(trans_p[prev_state][state])\n",
    "                if tr_prob > max_tr_prob:\n",
    "                    max_tr_prob = tr_prob\n",
    "                    prev_state_selected = prev_state\n",
    "\n",
    "            \n",
    "            max_prob = max_tr_prob + np.log(normal_dist(obs[t][0] , means[state][0] , sd[state][0]))\n",
    "            problist[t][state] = max_prob\n",
    "            prevlist[t][state] = prev_state_selected\n",
    "\n",
    "\n",
    "    opt = []\n",
    "    max_prob = float('-inf')\n",
    "    best_state = -1\n",
    "    # Get most probable state and its backtrack\n",
    "    for state in range(states):\n",
    "        if problist[len(obs)-1][state] > max_prob:\n",
    "            max_prob = problist[len(obs)-1][state]\n",
    "            best_state = state\n",
    "\n",
    "\n",
    "    opt.append(best_state)\n",
    "    previous = best_state\n",
    "\n",
    "    \n",
    "    for t in range(len(problist) - 2, -1, -1):\n",
    "        opt.insert(0, prevlist[t + 1][previous])\n",
    "        previous = int(prevlist[t + 1][previous])\n",
    "\n",
    "\n",
    "    opt = [int(x) for x in opt]\n",
    "\n",
    "    return opt\n",
    "    # print(opt)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = viterbi()\n",
    "# print(output.shape)\n",
    "\n",
    "output_list = ['\"El Nino\"' if output[i] == 0 else '\"La Nina\"' for i in range(len(output))]\n",
    "\n",
    "with open('states_Viterbi_wo_learning.txt', 'w') as f:\n",
    "    for item in output_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "\n",
    "\n",
    "# with open('sir2.txt') as f:\n",
    "#     sirer_output_list = [line.rstrip() for line in f]\n",
    "\n",
    "# accuracy_score(sirer_output_list , output_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(initial_distribution , transition_matrix , means , sd):\n",
    "    alpha = np.zeros((obs.shape[0], transition_matrix.shape[0]))\n",
    "    for i in range(states):\n",
    "        alpha[0][i] = initial_distribution[i][0] * normal_dist(obs[0][0] , means[i][0] , sd[i][0] )\n",
    "\n",
    "    for i in range(1, obs.shape[0]):\n",
    "        for j in range(trans_p.shape[0]):\n",
    "            alpha[i][j] = alpha[i - 1].dot(transition_matrix[:, j]) * normal_dist(obs[i][0] , means[j][0],sd[j][0])\n",
    "\n",
    "        alpha[i] = alpha[i] / (np.sum(alpha[i]))\n",
    "        \n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(transition_matrix , means , sd):\n",
    "    beta = np.zeros((obs.shape[0], transition_matrix.shape[0]))\n",
    "\n",
    "    beta[obs.shape[0] - 1] = np.ones((transition_matrix.shape[0]))\n",
    "\n",
    "    mult = np.zeros((states))\n",
    "  \n",
    "    for i in range(obs.shape[0] - 2, -1, -1):\n",
    "        for j in range(transition_matrix.shape[0]):\n",
    "            for k in range(states):\n",
    "                mult[k] = beta[i+1][k] * normal_dist(obs[i+1][0] , means[k][0] , sd[k][0] )\n",
    "\n",
    "           \n",
    "            beta[i][j] = mult .dot(trans_p[j, :])\n",
    "\n",
    "            \n",
    "        beta[i] = beta[i] / np.sum(beta[i]) \n",
    "        \n",
    "\n",
    "    return beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch(transition_matrix , means , sd , itr):\n",
    "    \n",
    "\n",
    "    for _ in range(itr):\n",
    "\n",
    "        initial_distribution = initial_probability(transition_matrix)\n",
    "\n",
    "        \n",
    "        alpha = forward(initial_distribution , transition_matrix , means , sd)\n",
    "        beta = backward(transition_matrix , means , sd)\n",
    "\n",
    "        \n",
    "\n",
    "        pi_star = alpha * beta\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(len(obs)):\n",
    "            pi_star[i] = pi_star[i] / (np.sum(pi_star[i]))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        pi_star_star = np.zeros((len(obs)-1 , states , states))\n",
    "\n",
    "        for i in range(len(obs)-1):\n",
    "            for j in range(states):\n",
    "                for k in range(states):\n",
    "                    pi_star_star[i][j][k] = alpha[i][j] * transition_matrix[j][k] * normal_dist(obs[i+1][0] ,  means[k][0] , sd[k][0]) * beta[i+1][k]\n",
    "\n",
    "\n",
    "\n",
    "        # print(pi_star_star)\n",
    "\n",
    "        \n",
    "\n",
    "        for i in range(len(obs)-1):\n",
    "            pi_star_star[i] = pi_star_star[i] / (np.sum(pi_star_star[i]) ) \n",
    "\n",
    "\n",
    "          \n",
    "\n",
    "\n",
    "        transition_matrix = np.zeros((states,states))\n",
    "\n",
    "        \n",
    "        for j in range(states):\n",
    "            for k in range(states):\n",
    "                for i in range(len(obs)-1):\n",
    "                    transition_matrix[j][k] = transition_matrix[j][k] + pi_star_star[i][j][k]\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "        for i in range(states):\n",
    "            transition_matrix[i] = transition_matrix[i] /( np.sum(transition_matrix[i]) )\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        for i in range(states):\n",
    "            means[i][0] =  np.sum((pi_star[:,i].reshape(-1,1) * obs))  / np.sum(pi_star[:,i]) \n",
    "            data_minus_mean_sq = (obs - means[i][0]) ** 2\n",
    "            sd[i][0] = np.sqrt( np.sum(pi_star[:,i].reshape(-1,1) * data_minus_mean_sq)  / np.sum(pi_star[:,i]))\n",
    "\n",
    "\n",
    "    initial_distribution = initial_probability(transition_matrix)\n",
    "\n",
    "    # print(initial_distribution)\n",
    "\n",
    "    return means , sd , transition_matrix , initial_distribution\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "means , sd , transition_matrix , distribution = baum_welch(trans_p , means , sd ,10)\n",
    "\n",
    "with open('parameters_learned.txt', 'w') as f:\n",
    "    f.write(\"%s\\n\" % str(states))\n",
    "    for i in range(states):\n",
    "        for j in range(states):\n",
    "            f.write(\"%s \" % str(transition_matrix[i][j]))\n",
    "\n",
    "        f.write(\"\\n\")  \n",
    "\n",
    "    for i in range(states):\n",
    "        f.write(\"%s \" % str(means[i][0]))\n",
    "\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    for i in range(states):\n",
    "        f.write(\"%s \" % str(sd[i][0] ** 2))\n",
    "        \n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    for i in range(states):\n",
    "        f.write(\"%s \" % str(distribution[i][0]))\n",
    "        \n",
    "    f.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 1084,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_p = transition_matrix\n",
    "start_p = distribution\n",
    "\n",
    "output = viterbi()\n",
    "\n",
    "output_list = ['\"El Nino\"' if output[i] == 0 else '\"La Nina\"' for i in range(len(output))]\n",
    "\n",
    "with open('states_Viterbi_after_learning.txt', 'w') as f:\n",
    "    for item in output_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "with open('sir2.txt') as f:\n",
    "    sirer_output_list = [line.rstrip() for line in f]\n",
    "\n",
    "accuracy_score(sirer_output_list , output_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
