{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = np.loadtxt(\"data.txt\", dtype=float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs.reshape(-1,1)\n",
    "\n",
    "# obs[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramfile = \"parameters.txt\"\n",
    "states = 0\n",
    "with open(paramfile) as f:\n",
    "    states = int(f.readline().strip())\n",
    "\n",
    "\n",
    "trans_p = np.loadtxt(paramfile , dtype = float , skiprows = 1 , max_rows = states )\n",
    "\n",
    "means = np.loadtxt(paramfile , dtype = float , skiprows = states + 1  , max_rows = 1 ).reshape(-1,1)\n",
    "\n",
    "sd = np.loadtxt(paramfile , dtype = float , skiprows = states + 2  , max_rows = 1 ).reshape(-1,1)\n",
    "# trans_p\n",
    "# means[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros([states,1] , float)\n",
    "b[states-1][0] = 1\n",
    "\n",
    "trans_p_copy = np.copy(trans_p)\n",
    "a = trans_p_copy[:,:states-1]\n",
    "\n",
    "\n",
    "for i in range(0,states-1):\n",
    "    a[i][i] = a[i][i] - 1\n",
    "\n",
    "a = np.vstack((a , np.ones([states,1]))).reshape(states,states)\n",
    "\n",
    "start_p = np.linalg.solve(a , b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_dist(x , mean , sd):\n",
    "    prob_density = norm.pdf(x, loc=mean, scale=np.sqrt(sd))\n",
    "    if prob_density == 0:\n",
    "        prob_density = 1e-250\n",
    "    return prob_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi():\n",
    "\n",
    "    problist = np.zeros([len(obs), states])\n",
    "    prevlist = np.zeros([len(obs), states])\n",
    "\n",
    "    for state in range(states):\n",
    "        problist[0][state] = np.log(start_p[state] * normal_dist(obs[0][0] , means[0][0], sd[0][0]))\n",
    "        prevlist[0][state] = -1\n",
    "\n",
    "  \n",
    "    for t in range(1, len(obs)):\n",
    "        \n",
    "        for state in range(states):\n",
    "            max_tr_prob = problist[t-1][0] + np.log(trans_p[0][state])\n",
    "            prev_state_selected = 0\n",
    "\n",
    "            for prev_state in range(1,states):\n",
    "                tr_prob = problist[t - 1][prev_state] + np.log(trans_p[prev_state][state])\n",
    "                if tr_prob > max_tr_prob:\n",
    "                    max_tr_prob = tr_prob\n",
    "                    prev_state_selected = prev_state\n",
    "\n",
    "            \n",
    "            max_prob = max_tr_prob + np.log(normal_dist(obs[t][0] , means[state][0] , sd[state][0]))\n",
    "            problist[t][state] = max_prob\n",
    "            prevlist[t][state] = prev_state_selected\n",
    "\n",
    "\n",
    "    opt = []\n",
    "    max_prob = float('-inf')\n",
    "    best_state = -1\n",
    "    # Get most probable state and its backtrack\n",
    "    for state in range(states):\n",
    "        if problist[len(obs)-1][state] > max_prob:\n",
    "            max_prob = problist[len(obs)-1][state]\n",
    "            best_state = state\n",
    "\n",
    "\n",
    "    opt.append(best_state)\n",
    "    previous = best_state\n",
    "\n",
    "    \n",
    "    for t in range(len(problist) - 2, -1, -1):\n",
    "        opt.insert(0, prevlist[t + 1][previous])\n",
    "        previous = int(prevlist[t + 1][previous])\n",
    "\n",
    "\n",
    "    opt = [int(x) for x in opt]\n",
    "\n",
    "    return opt\n",
    "    # print(opt)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 1041,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output = viterbi()\n",
    "# print(output.shape)\n",
    "\n",
    "output_list = ['\"El Nino\"' if output[i] == 0 else '\"La Nina\"' for i in range(len(output))]\n",
    "\n",
    "with open('states_Viterbi_wo_learning.txt', 'w') as f:\n",
    "    for item in output_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "\n",
    "\n",
    "with open('sir.txt') as f:\n",
    "    sirer_output_list = [line.rstrip() for line in f]\n",
    "\n",
    "accuracy_score(sirer_output_list , output_list)\n",
    "\n",
    "# sirer_output_list\n",
    "\n",
    "# output_list"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
